{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchtext Code Along & Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB!** The current (30/3/2018) release of PyTorch Torchtext has some bugs preventing execution of this notebook. The updated version of Torchtext used in this notebook can be retrieved via:\n",
    "```\n",
    "pip install --upgrade git+https://github.com/pytorch/text\n",
    "```\n",
    "\n",
    "-- Wayne Nixalo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import torch\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = pathlib.Path('../../data/')\n",
    "comp  = pathlib.Path('competitions/jigsaw-toxic-comment-classification-challenge/')\n",
    "TRAIN_DATA_FILE = pathlib.Path('train.csv')\n",
    "TEST_DATA_FILE  = pathlib.Path('test.csv')\n",
    "\n",
    "device=0 # index of GPU. -1:CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Declare Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Construct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 1.25 s, total: 23 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv_datafields = [(\"id\", None),      (\"comment_text\", TEXT), \n",
    "                 (\"toxic\", LABEL),  (\"severe_toxic\", LABEL), \n",
    "                 (\"threat\", LABEL), (\"obscene\", LABEL), \n",
    "                 (\"insult\", LABEL), (\"identity_hate\", LABEL)]\n",
    "trn, vld = TabularDataset.splits(\n",
    "        path=path/comp,\n",
    "        train=TRAIN_DATA_FILE, validation=TRAIN_DATA_FILE,\n",
    "        format='csv', skip_header=True,\n",
    "        fields=tv_datafields)\n",
    "\n",
    "# for the test data we don't have any labels\n",
    "tst_datafields = [(\"id\", None), (\"comment_text\", TEXT)]\n",
    "\n",
    "tst = TabularDataset(\n",
    "        path=path/comp/TEST_DATA_FILE,\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tst_datafields)\n",
    "\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Constructing the Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    "    (trn, vld),  # datasets for Iterator to draw data from\n",
    "    batch_sizes=(64,64),\n",
    "    device=device, # GPU/CPU\n",
    "    sort_key = lambda x: len(x.comment_text), # fn to group data with (here: comment length)\n",
    "    sort_within_batch=False,\n",
    "    repeat=False # this Iterator will be wrapped\n",
    ")\n",
    "\n",
    "# test set shouldn't be shuffled ==> use standard Iterator\n",
    "test_iter = Iterator(\n",
    "    tst, batch_size=64, device=device, sort=False, \n",
    "    sort_within_batch=False, repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Wrapping the Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x, y):\n",
    "        self.dl, self.x, self.y = dl, x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x) # assuming only 1 input in this wrapper\n",
    "\n",
    "            if self.y is not None: # we'll cocncat y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x,y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"comment_text\", list(trn.fields.keys())[2:])\n",
    "valid_dl = BatchWrapper(val_iter, \"comment_text\", list(trn.fields.keys())[2:])\n",
    "test_dl  = BatchWrapper(test_iter, \"comment_text\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Architecture -- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300,\n",
    "                 spatial_dropout=0.05, recurrent_dropout=0.1, num_linear=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=recurrent_dropout, bidirectional=False)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 6)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTMBaseline(\n",
       "  (embedding): Embedding(470342, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList(\n",
       "  )\n",
       "  (predictor): Linear(in_features=500, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleLSTMBaseline(nh, emb_dim=emb_sz)\n",
    "\n",
    "if device != -1:\n",
    "    model.cuda()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.1)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # we can easily iterate over our data thanks to our wrapper\n",
    "        opt.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = loss_fn(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.data[0] * x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    # calculate validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in valid_dl:\n",
    "        preds = model(x)\n",
    "        loss = loss_fn(preds, y)\n",
    "        val_loss += loss.data[0] * x.size(0)\n",
    "        \n",
    "    val_loss /= len(vld)\n",
    "    print(f'Epoch: {epoch}, Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Writing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2394/2394 [03:59<00:00, 10.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for x, y in tqdm.tqdm(test_dl):\n",
    "    preds = model(x)\n",
    "    # if your data is on the GPU you need to move it back to the CPU\n",
    "    preds = preds.data.cpu().numpy()\n",
    "    # preds = preds.data.numpy()\n",
    "    # the actual outputs of the model are logits, so we need to pass these \n",
    "    # values to the sigmoid function\n",
    "    preds = 1 / (1 + np.exp(-preds))\n",
    "    test_preds.append(preds)\n",
    "test_preds = np.concatenate(test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/comp/\"sample_submission.csv\")\n",
    "for i,col in enumerate([\"toxic\",\"severe_toxic\",\"threat\",\"obscene\",\"insult\",\"identity_hate\"]):\n",
    "    df[col] = test_preds[:, i]\n",
    "df.to_csv(path/comp/\"submission_torchtext_LSTM_00.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run with Light Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path  = pathlib.Path('../../data/')\n",
    "comp  = pathlib.Path('competitions/jigsaw-toxic-comment-classification-challenge/')\n",
    "TRAIN_DATA_FILE = pathlib.Path('train.csv')\n",
    "TEST_DATA_FILE  = pathlib.Path('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***NOTE***: Specify `device=0` to use GPU:0, else `=-1` for CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device=0 # index of GPU. -1:CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ~~Fill Missing Values~~\n",
    "\n",
    "(not needed in updated torchtext: `torchtext.data.Field` class already specifies `<unk>` token for unknown words. -- Does this handle empty fields? Yes: the Torchtext dataloader automatically zero-pads sequences in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(path/comp/TRAIN_DATA_FILE)\n",
    "# test  = pd.read_csv(path/comp/TEST_DATA_FILE)\n",
    "\n",
    "# train[\"comment_text\"] = train[\"comment_text\"].fillna(\"_na_\").values\n",
    "# test[\"comment_text\"]  = test[\"comment_text\"].fillna(\"_na_\").values\n",
    "\n",
    "# # update paths to copies on disk\n",
    "# TRAIN_DATA_FILE = pathlib.Path('nafill_' + str(TRAIN_DATA_FILE))\n",
    "# TEST_DATA_FILE  = pathlib.Path('nafill_' + str(TEST_DATA_FILE))\n",
    "\n",
    "# train.to_csv(path/comp/TRAIN_DATA_FILE)\n",
    "# test.to_csv(path/comp/TEST_DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Declare Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`torchtext.data.Field` class determines how data is preprocessed and converted into numeric format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Want \"comment_text\" field to be lowercase, tokenized on whitespace, and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Labels are already in binary encoding. Just need tell `Field` that they're already processed. Do this with `use_vocab=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Construct Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TabularDataset handles CSV, TSV, and JSON data reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 1.25 s, total: 23 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv_datafields = [(\"id\", None),      (\"comment_text\", TEXT), \n",
    "                 (\"toxic\", LABEL),  (\"severe_toxic\", LABEL), \n",
    "                 (\"threat\", LABEL), (\"obscene\", LABEL), \n",
    "                 (\"insult\", LABEL), (\"identity_hate\", LABEL)]\n",
    "trn, vld = TabularDataset.splits(\n",
    "        path=path/comp,\n",
    "        train=TRAIN_DATA_FILE, validation=TRAIN_DATA_FILE,\n",
    "        format='csv', skip_header=True,\n",
    "        fields=tv_datafields)\n",
    "\n",
    "# for the test data we don't have any labels\n",
    "tst_datafields = [(\"id\", None), (\"comment_text\", TEXT)]\n",
    "\n",
    "tst = TabularDataset(\n",
    "        path=path/comp/TEST_DATA_FILE,\n",
    "#         test=TEST_DATA_FILE,\n",
    "#         path='../../data/competitions/jigsaw-toxic-comment-classification-challenge/test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=tst_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's instructive to take a look inside the Dataset. Datasets can be indexed like normal lists, so looking at the first element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x7f97ef12e7f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `Example` object bundles the attributes of a single datapoint together. At this point the text has been tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['comment_text', 'toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation', 'why', 'the']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].comment_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the `TEXT` field to convert words to integers, it needs to be told what the entire vocabulary is. To do this, we run `TEXT.build_vocab`, passing in the dataset to build the vocabulary on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 68 ms, total: 3.95 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`vocab.freqs` is a `collections.Counter` object, so we can take a look at the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 490031),\n",
       " ('to', 294069),\n",
       " ('of', 222834),\n",
       " ('and', 218120),\n",
       " ('a', 211778),\n",
       " ('i', 196695),\n",
       " ('you', 187782),\n",
       " ('is', 170753),\n",
       " ('that', 146478),\n",
       " ('in', 140540)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This makes Torchtext go through all the elements in the training set, check the contents corresponding to the `TEXT` field, and register the words in its vocabulary. Torchtext has its own class called `Vocab` for handling the vocabulary. The `Vocab` class holds a mapping frm word to id in its `stoi` attribute and a reverse mapping in its `itos` attribute. In addition to this, it cn automatically build an embedding matrix for you using various pretrained embeddings like word2vec. The `Vocab` class can also take options like `max_size` and `min_freq` that dictate how many words are in the vocabulary or how many times a word has to appear to be registered in the vocabulary. Words that aren't included in the vocabulary will be converted into `<unk>`, the \"unknown\" token.\n",
    "\n",
    "Now that we have our data formatted and read into memeory, we turn to the next step: creating an Iterator to pass the data to our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Constructing the Iterator\n",
    "\n",
    "'Iterator' is the Torchtext DataLoader with some extra NLP-specific functionalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`BucketIterator` automatically shuffles & buckets input sequences into seqs of similar length. Allows for efficient padding. You *must* tell `BucketIterator` what attribute you want to bucket the data on.\n",
    "\n",
    "Here we want to bucket based on lengths of `comment_text` field. For test data, we don't want to shuffle since we'll be outputting predictions at end fo training -- that's why we use a standard `Iterator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    "    (trn, vld),  # datasets for Iterator to draw data from\n",
    "    batch_sizes=(64,64),\n",
    "    device=device, # GPU/CPU\n",
    "    sort_key = lambda x: len(x.comment_text), # fn to group data with (here: comment length)\n",
    "    sort_within_batch=False,\n",
    "    repeat=False # this Iterator will be wrapped\n",
    ")\n",
    "\n",
    "# test set shouldn't be shuffled ==> use standard Iterator\n",
    "test_iter = Iterator(\n",
    "    tst, batch_size=64, device=device, sort=False, \n",
    "    sort_within_batch=False, repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Output of `BucketIterator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.comment_text]:[torch.cuda.LongTensor of size 22x64 (GPU 0)]\n",
       "\t[.toxic]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       "\t[.severe_toxic]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       "\t[.threat]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       "\t[.obscene]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       "\t[.insult]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
       "\t[.identity_hate]:[torch.cuda.LongTensor of size 64 (GPU 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(train_iter.__iter__()); batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.comment_text]:[torch.cuda.LongTensor of size 290x64 (GPU 0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(test_iter.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The length of the `.comment_text` tensor is determined by the max-length comment in that minibatch.\n",
    "\n",
    "The batch has all the fields we passed to the Dataset as attributes. The batch data can be accessed through the attribute with the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'dataset', 'train', 'fields', 'comment_text', 'toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Wrapping the Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `Iterator` returns a custom datatype: `torch.data.Batch` `Batch` has similar API to `Example`: w/ a batch of data from each field as attributes. We can use a simple wrapper to ease use. $\\longrightarrow$ convert `Batch` to tuple: (x, y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x, y):\n",
    "        self.dl, self.x, self.y = dl, x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x) # assuming only 1 input in this wrapper\n",
    "\n",
    "            if self.y is not None: # we'll cocncat y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x,y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"comment_text\", list(trn.fields.keys())[2:])\n",
    "\n",
    "valid_dl = BatchWrapper(val_iter, \"comment_text\", list(trn.fields.keys())[2:])\n",
    "\n",
    "test_dl  = BatchWrapper(test_iter, \"comment_text\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'comment_text', 'toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate'])\n",
      "['toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "print(trn.fields.keys())\n",
    "print(list(trn.fields.keys())[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All we're doing here is converting the `Batch` object into a tuple of inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  4.0099e+05  1.0910e+03  5.5000e+01  ...   1.0690e+03  1.6950e+03  1.2500e+02\n",
       "  4.6200e+02  1.1468e+05  5.9000e+01  ...   2.7000e+01  2.0000e+00  1.3000e+01\n",
       "  2.8000e+01  9.0000e+00  1.3600e+02  ...   7.0000e+00  9.9200e+02  4.1500e+02\n",
       "                 ...                   ⋱                   ...                \n",
       "  5.4600e+02  2.0000e+00  2.8550e+03  ...   2.6400e+02  1.2000e+01  2.0940e+03\n",
       "  2.5700e+02  2.4137e+05  3.0416e+04  ...   3.5927e+04  1.8400e+03  1.3000e+01\n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  ...   1.5373e+04  2.6000e+02  5.8690e+03\n",
       " [torch.cuda.LongTensor of size 38x64 (GPU 0)], Variable containing:\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     1     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     1     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       " [torch.cuda.FloatTensor of size 64x6 (GPU 0)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.0000e+00  1.8000e+01  3.9310e+03  ...   1.8000e+01  4.4400e+02  1.8000e+01\n",
       "  3.9500e+02  3.4705e+04  7.0000e+00  ...   1.1371e+04  1.1730e+03  1.9780e+03\n",
       "  0.0000e+00  7.0000e+00  2.2430e+03  ...   1.0783e+04  2.9600e+02  8.0000e+00\n",
       "                 ...                   ⋱                   ...                \n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  ...   1.0000e+00  1.0000e+00  1.0000e+00\n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  ...   1.0000e+00  1.0000e+00  1.0000e+00\n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  ...   1.0000e+00  1.0000e+00  1.0000e+00\n",
       " [torch.cuda.LongTensor of size 764x64 (GPU 0)], \n",
       "  0\n",
       " [torch.FloatTensor of size 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(test_dl.__iter__()) # this wont screw up ordering will it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we're ready to start training a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Training a Text Classifier -- LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll use a simple LSTM as a baseline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300,\n",
    "                 spatial_dropout=0.05, recurrent_dropout=0.1, num_linear=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=recurrent_dropout, bidirectional=False)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 6)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTMBaseline(\n",
       "  (embedding): Embedding(470342, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList(\n",
       "  )\n",
       "  (predictor): Linear(in_features=500, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleLSTMBaseline(nh, emb_dim=emb_sz)\n",
    "\n",
    "if device != -1:\n",
    "    model.cuda()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can iterate using our wrapped `Iterator`, and the data will automatically be passed to us after being moved to the GPU and numericalized appropriately.\n",
    "\n",
    "***NB***: RNNs suffer from gradient instability without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# opt = optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.1)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [02:59<00:00, 13.87it/s]\n",
      "  0%|          | 0/2494 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.0740, Validation Loss: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [03:00<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.0510, Validation Loss: 0.0467\n",
      "CPU times: user 5min 8s, sys: 2min 5s, total: 7min 13s\n",
      "Wall time: 7min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs+1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # we can easily iterate over our data thanks to our wrapper\n",
    "        opt.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = loss_fn(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.data[0] * x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    # calculate validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in valid_dl:\n",
    "        preds = model(x)\n",
    "        loss = loss_fn(preds, y)\n",
    "        val_loss += loss.data[0] * x.size(0)\n",
    "        \n",
    "    val_loss /= len(vld)\n",
    "    print(f'Epoch: {epoch}, Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Writing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BatchWrapper at 0x7fb044a6f048>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2394/2394 [03:59<00:00, 10.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for x, y in tqdm.tqdm(test_dl):\n",
    "    preds = model(x)\n",
    "    # if your data is on the GPU you need to move it back to the CPU\n",
    "    preds = preds.data.cpu().numpy()\n",
    "    # preds = preds.data.numpy()\n",
    "    # the actual outputs of the model are logits, so we need to pass these \n",
    "    # values to the sigmoid function\n",
    "    preds = 1 / (1 + np.exp(-preds))\n",
    "    test_preds.append(preds)\n",
    "test_preds = np.concatenate(test_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# quick save\n",
    "# pickle.dump(test_preds, open(path/comp/'test_preds_temp.pkl', 'wb'))\n",
    "\n",
    "# quick load\n",
    "# file = open(path/comp/'test_preds_temp.pkl', 'rb')\n",
    "# test_preds = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/comp/\"sample_submission.csv\")\n",
    "for i,col in enumerate([\"toxic\",\"severe_toxic\",\"threat\",\"obscene\",\"insult\",\"identity_hate\"]):\n",
    "    df[col] = test_preds[:, i]\n",
    "    \n",
    "# df.drop(\"comment_text\", axis=1).to_csv(path/comp/\"submission_torchtext_LSTM_00.csv\", index=False)\n",
    "df.to_csv(path/comp/\"submission_torchtext_LSTM_00.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.037026</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.925357</td>\n",
       "      <td>0.018958</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.541257</td>\n",
       "      <td>0.468671</td>\n",
       "      <td>0.033942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.008045      0.000083  0.000011  0.000283  0.000305   \n",
       "1  0000247867823ef7  0.037026      0.000122  0.000082  0.000841  0.001089   \n",
       "2  00013b17ad220c46  0.925357      0.018958  0.001791  0.541257  0.468671   \n",
       "3  00017563c3f7919a  0.017331      0.000181  0.000062  0.000273  0.000500   \n",
       "4  00017695ad8997eb  0.003544      0.000033  0.000013  0.000162  0.000174   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.000103  \n",
       "1       0.000864  \n",
       "2       0.033942  \n",
       "3       0.000267  \n",
       "4       0.000116  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/comp/\"submission_torchtext_LSTM_00.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A previous submission (Keras/TensorFlow LSTM using GloVe embeddings and dropout) for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.992614</td>\n",
       "      <td>4.229196e-01</td>\n",
       "      <td>0.943973</td>\n",
       "      <td>0.068383</td>\n",
       "      <td>0.884356</td>\n",
       "      <td>0.297003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>7.136537e-07</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>3.640881e-06</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>1.288999e-06</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>1.352115e-05</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.992614  4.229196e-01  0.943973  0.068383  0.884356   \n",
       "1  0000247867823ef7  0.000673  7.136537e-07  0.000113  0.000002  0.000055   \n",
       "2  00013b17ad220c46  0.001434  3.640881e-06  0.000333  0.000005  0.000125   \n",
       "3  00017563c3f7919a  0.001091  1.288999e-06  0.000130  0.000006  0.000094   \n",
       "4  00017695ad8997eb  0.006187  1.352115e-05  0.000948  0.000036  0.000619   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.297003  \n",
       "1       0.000021  \n",
       "2       0.000047  \n",
       "3       0.000016  \n",
       "4       0.000126  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/comp/\"submission_LSTM_glove_01.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model gets a 0.5 score. Checking above, this is not due to shuffling the test-set, the data is in proper order. Instead the LSTM hasn't 'learned' how to classify the data yet.\n",
    "\n",
    "That being said, this represents a successful baseline for training and submitting a Torchtext NLP model. With the PyTorch-specific mechanics handled (data preprocessing, loading, etc), the design can easily be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Checking `test_dl` loading properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import torch\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path  = pathlib.Path('../../data/')\n",
    "comp  = pathlib.Path('competitions/jigsaw-toxic-comment-classification-challenge/')\n",
    "TRAIN_DATA_FILE = pathlib.Path('train.csv')\n",
    "TEST_DATA_FILE  = pathlib.Path('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_to_test_data_file = '../../data/competitions/jigsaw-toxic-comment-classification-challenge/test.csv'\n",
    "alt_path_to_test_data_file = 'practical-torchtext/data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = {0:path/comp/TEST_DATA_FILE, 1:path_to_test_data_file, 2:alt_path_to_test_data_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x, y):\n",
    "        self.dl, self.x, self.y = dl, x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x) # assuming only 1 input in this wrapper\n",
    "\n",
    "            if self.y is not None: # we'll cocncat y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x,y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tst_datafields = [(\"id\",None), (\"comment_text\", TEXT)]\n",
    "tst = TabularDataset(path=PATH[2], format='csv', \n",
    "                     skip_header=True, fields=tst_datafields)\n",
    "test_iter = Iterator(tst, batch_size=64, device=device, sort=False,\n",
    "                     sort_within_batch=False, repeat=False)\n",
    "test_dl = BatchWrapper(test_iter, \"comment_text\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# build vocab (numericalize)\n",
    "TEXT.build_vocab(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "   197   193   199  ...     18   664   192\n",
       "   493   128   294  ...      6    22     5\n",
       "    75    15     6  ...    118   310    17\n",
       "        ...          ⋱          ...       \n",
       "     1     1     1  ...      1     1     1\n",
       "     1     1     1  ...      1     1     1\n",
       "     1     1     1  ...      1     1     1\n",
       " [torch.cuda.LongTensor of size 158x33 (GPU 0)], \n",
       "  0\n",
       " [torch.FloatTensor of size 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(test_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Note Heavy partial walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path  = pathlib.Path('../../data/')\n",
    "comp  = pathlib.Path('competitions/jigsaw-toxic-comment-classification-challenge/')\n",
    "TRAIN = pathlib.Path(path/comp/'train.csv')\n",
    "TEST  = pathlib.Path(path/comp/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Read data from disk\n",
    "2. Tokenize text\n",
    "3. Create word-unique-integer mappings\n",
    "4. Convert text to list of integers\n",
    "5. Load data into format req'd by DL framekwork\n",
    "6. Pad text so all seqs same len ==> for batch processing\n",
    "\n",
    "Torchtext follows the basic formula for transforming data into working input for your neural network:\n",
    "\n",
    "<img src=\"https://i0.wp.com/mlexplained.com/wp-content/uploads/2018/02/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88-2018-02-07-10.32.59.png?w=1500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2. Declaring Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Torch text takes a declarative approach to laoding its data: you tell torchtext how you want the data to look, and torchtext hands it for you.\n",
    "\n",
    "The way you do this is by declaring a Field. The Field specifies how you want a certain (you guessed it) field to be processed. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "tokenize = lambda x : x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)\n",
    "\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the Toxic Comment Classification dataset there are 2 kinds of fields: the common text and the labels (toxic, severe toxic, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(TRAIN).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you're passing a field that's already numericalized by default and not sequential, you should pass `use_vocab=False` and `sequential=False`\n",
    "\n",
    "For the comment text, we pass in the preprocessing we want the field to do as keyword arguents. We give it the tokenizer we want the field to use, tell it to convert the input to lowercase, and also tell it the input is sequential.\n",
    "\n",
    "In addition to the keyword arguments mentioned above, the Field class also allows the user to speciy special tokens (the `unk_token` for out-of-vocab words, the `pad_token` for padding, `eos_token` for end-of-sentence, and an optional `init_token` for the start of a sentence), choose whether to make the first dimension the batch or the sequence (the 1st dim is the seq by default), and choose whether to allow the sequence lengths to be decided at runtime or in advance. Fortunately, [the docstrings](https://github.com/pytorch/text/blob/c839a7934930819be7e240ea972e4d600966afdc/torchtext/data/field.py#L61) for the **Field** class are relatively well written, so if you need some advanced preprocessing you should refer to them for more information.\n",
    "\n",
    "The **Field** class is at the center of torchtext and is what makes preprocessing such an ease. Aside from the standard field class, here's a list of the fields that are currently available (along w/ their use cases):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "|Name | Description | Use Case|\n",
    "|-----|-------------|---------|\n",
    "|Field|A regular field that defines preprocessing and post processing|Non-text fields and text fields where you don't need to map integers back to words.|\n",
    "|ReversibleField|An extension of the field that allows reverse mapping of word ids to words|Text fields if you want to map the integers back to natural language (such as in the case of language modeling)|\n",
    "|NestedField|A field that processes non-tokenized text into a set of smaller fields|Char-based models|\n",
    "|LabelField (New!)|A regular field with `sequential=False` and no `<unk>` token. Newly added on the master branch.|Label fields in text classification|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3. Constructing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The fields know what to do when given raw data. Now we need to tell the fields what data they should work on. This is where we use Datasets.\n",
    "\n",
    "There're various built-in Datasets in torchtext that handle common data formats. For CSV/TSV fiels the **`TabularDataset`** class is convenient. Here's how we'd read data from a CSV file using `TabularDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "tv_datafields = [(\"id\", None), # we won't be needing the id, so we pass None as the field\n",
    "                 (\"comment_text\", TEXT), (\"toxic\", LABEL), \n",
    "                 (\"severe_toxic\", LABEL), (\"threat\", LABEL), \n",
    "                 (\"obscene\", LABEL), (\"insult\", LABEL), (\"identity_hate\", LABEL)]\n",
    "trn, vld = TabularDataset.splits(\n",
    "                path=path/comp, # the root directory where the data lies\n",
    "                train='train.csv', validation='train.csv',\n",
    "                format='csv',\n",
    "                skip_header=True, # if your csv has a header, make sure to pass this to ensure it doesn't get processed as data!\n",
    "                fields=tv_datafields)\n",
    "tst_datafields = [(\"id\", None), # we won't be needing the id, so we pass in Noen as the field\n",
    "                  (\"comment_text\", TEXT)]\n",
    "tst = TabularDataset(\n",
    "            path=TRAIN, # the file path\n",
    "            format='csv',\n",
    "            skip_header=True,\n",
    "            fields=tst_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the `TabularDataset`, we pass in a list of (name, field) pairs as the fields argument. The fields we pass in must be in the same order as the columns. For the columns we don't use, we pass in a tuple where the field element is None.\n",
    "\n",
    "The splits method creates a dataset for the train and validation data by applying the same processing. It can also handle the data, but since our test data has a different frmat from the train and validation data, we create a different dataset.\n",
    "\n",
    "Datasets can mostly be treated in the same way as lists. To understand this, it's instructive to take a look inside our Dataset. Datasets can be indexed and iterated over like normal lists, so let's see what the first element looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn[1].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn[0].comment_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn[1].comment_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Torchtext handles mapping words to integers, but it has to be told the full range of words it should handle. In our case, we probably want to build the vocabulary on the training set only, so we run the following code: `TEXT.build_vocab(trn)`\n",
    "\n",
    "This makes torchtext go through all the elements in the training set, check the contents corresp----\n",
    "\n",
    "---\n",
    "\n",
    "List of currently available datasets and the format of data they take:\n",
    "\n",
    "|Name|Description|Use Case|\n",
    "|-|-|-|\n",
    "|`TabularDataset`|Takes the path to CSV/TSV and JSON files or Python dictionaries as inputs.|Any problem that involves a label (or labels) for each piece of text.|\n",
    "|`LanguageModelingDataset`|Takes the path to a text file.|Language modeling|\n",
    "|`TranslationDataset`|Takes a path and extensions to a file for each language. eg: If the files are English: \"hoge.en\", French: \"hoge.fr\", path=\"hoge\", exts=(\"en\",\"fr\")|Translation|\n",
    "|`SequenceTaggingDataset`|Takes a path to a file with the input sequence and output sequence separated by tabs.|Sequence tagging.|\n",
    "\n",
    "Now that we have our data formatted and read into memory, we turn to the next step: creating an iterator to pass the data to our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4. Constructing the Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In torchvision and PyTorch, the processing and batching of data is handled by DataLoaders. For some reason torchtext has renamed the objects that do the exact same thing to Iterators. The basic functionality is the same, but Iterators, as we will see, have some convenient functionality that is unique to NLP.\n",
    "\n",
    "Below is code for how you 'd initialize the Iterators for the train, validation, and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    "    (trn, vld), # we pass in the datasets we want the iterator to draw data from\n",
    "    batch_sizes=(64,64),\n",
    "    device=0, # if you want to use the GPU, specify GPU number here\n",
    "    sort_key=lambda x: len(x.comment_text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "    sort_within_batch=False,\n",
    "    repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")\n",
    "test_iter = Iterator(tst, batch_size=64, device=0, sort=False, sort_within_batch=False, repeat=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***NOTE***: using the `sort_within_batch` argument, when set to True, sorts the data within each minibatch indecreasing order acc. to the `sort_key`. This is necessary when you want to use `pack_padded_sequence` with the padded sequence data and convert the padded sequence tensor to a `PackedSequence` object.\n",
    "\n",
    "The `BucketIterator` is one of the most powerful features of torchtext. It automatically shuffles and buckets the input sequences into sequences of similar length.\n",
    "\n",
    "The reason this is powerful is that we need to pad the input sequennces to be of the same length to enable batch processing. For instance, the sequences:\n",
    "```\n",
    "[ [3, 15, 2, 7], \n",
    "  [4, 1], \n",
    "  [5, 5, 6, 8, 1] ]\n",
    "```\n",
    "would need to be padded to become:\n",
    "```\n",
    "[ [3, 15, 2, 7, 0],\n",
    "  [4, 1, 0, 0, 0],\n",
    "  [5, 5, 6, 8, 1] ]\n",
    "```\n",
    "\n",
    "The amount of padding necessary is determined by the longest sequence in the batch. Therefore, padding is most efficient when the sequences are of similar lengths. The BucketIterator does all this behind the scenes. As a word of caution, you need to tell the BucketIterator what attribute you want to bucket the data on. In our case, we want to bucket based on the lengths of the comment_text field, so we pass that in as a keyword argument.\n",
    "\n",
    "For the test data, we don't want to shuffle the data since we'll be ouputting the predictions at the end of training. This is why we use a standard iterator.\n",
    "\n",
    "---\n",
    "\n",
    "List of iterators that torchtext currently implements:\n",
    "\n",
    "|Name|Description|Use Case|\n",
    "|-|-|-|\n",
    "|`Iterator`|Iterates over the data in the order of the dataset.|Test data, or any other data where the order is important.|\n",
    "|`BucketIterator`|Buckets sequences of similar lengths together.|Text classification, sequence tagging, etc. (use cases where the input is of variable length)|\n",
    "|`BPTTIterator`|An iterator built especially for language modeling that also generates the input sequence delayed by one timestep. It also varies the BPTT length.|Language modeling|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5. Wrapping the Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Currently, the iterator returns a custom datatype called `torchtext.data.Batch`. The **`Batch`** class has a similar API to the `Example` type, with a batch of data from each field as attributes. Unfortunately, this custom datatype makes code reuse difficult (since each time the column names change, we need to modify the code), and makes torchtexk hard to use with other libraries for some use cases (like torchsample and fastai).\n",
    "\n",
    "In the meantime we'll hack on a simple wrapper to make the batches easy to use. Concretely, we'll convert the batch to a tuple in the form (x, y) where x is the independent variable (input) and y is the dependent variable (labels). Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl,self.x_var,self.y_vars = dl,x_var,y_vars\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is #TODO:\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeroes((1))\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "train_dl = BatchWrapper(train_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "valid_dl = BatchWrapper(val_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "test_dl = BatchWrapper(test_iter, \"comment_text\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
