{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM: GloVe + Dropout Code Along\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is a codealong of the [Improved LSTM baseline: GloVe + dropout](https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout) Kaggle kernel by Jeremy Howard.\n",
    "\n",
    "-- Wayne Nixalo - 30/3/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel is a somewhat improved version of [Keras - Bidirectional LSTM baseline](https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-051) along with some with some additional documentation of the steps (NB: this notebook has been re-run on the new test set.)\n",
    "\n",
    "The GloVe embeddings used can be found [here](https://www.kaggle.com/yliu9999/glove6b50d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import pathlib\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path('../../data/')\n",
    "comp = pathlib.Path('competitions/jigsaw-toxic-comment-classification-challenge')\n",
    "EMBEDDING_FILE  = pathlib.Path('glove/glove.6B.50d.txt')\n",
    "TRAIN_DATA_FILE = pathlib.Path(path/comp/'train.csv')\n",
    "TEST_DATA_FILE  = pathlib.Path(path/comp/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic config parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50 # how big is each word vector\n",
    "max_features = 20000 # how many unique words to use (ie: num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in our data and replace missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test  = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\n",
    "list_classes = [col for col in train.columns[2:]]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Keras preprocessing, to turn each comment into a list of word indices of equal length (with truncation or padding as needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test  = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t  = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test,  maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the GloVe word vectors (space delimited strings) into a dictionary from word->vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(path/EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these vectors to create our embedding matrix, with random intialization for words that aren't in GloVe. We'll use the same mean and stdev of embeddings the GloVe has when generating the random init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.020940498, 0.6441043)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean, emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "# emb matrix is initialized first\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # GloVe emb vector used if exists for word\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple bidirectional LSTM with two fully-connected layers. We add some dropout to the LSTM since even 2 eopchs is enough to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,)) # the comma sets it as a tuple\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(LSTM(embed_size, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(embed_size, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to fit our model! Use `validation_split` when not submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 1494s 10ms/step - loss: 0.0596 - acc: 0.9792 - val_loss: 0.0481 - val_acc: 0.9825\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 1470s 10ms/step - loss: 0.0444 - acc: 0.9833 - val_loss: 0.0461 - val_acc: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92045035f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, get predictions for the test set and prepare a submission CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 15s 100us/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_te], batch_size=1024, verbose=1)\n",
    "submission = pd.read_csv(path/comp/'sample_submission.csv')\n",
    "submission[list_classes] = y_test\n",
    "submission.to_csv(path/comp/'submission_LSTM_glove_00.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "LSTM trained with validation split removed:\n",
    "\n",
    "`0.9754`/**`0.9764`** -- 2969/4551: top 65.2%\n",
    "\n",
    "LSTM trained with entire training set:\n",
    "\n",
    "`0.9775`/**`0.9783`**-- 2746/4551: top 60.3 %\n",
    "\n",
    "*(1st place is 0.9885 private)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "Submissions were accidentally saved with Pandas indices - causing errors during submission. Both submission files are reloaded here and stripped of their index columns before being resaved.\n",
    "\n",
    "[Removing index column in pandas\n",
    "](https://stackoverflow.com/questions/20107570/removing-index-column-in-pandas) | [Delete column from pandas DataFrame](https://stackoverflow.com/a/18145399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    sub_name = f'submission_LSTM_glove_0{str(i)}.csv'\n",
    "    sub = pd.read_csv(path/comp/sub_name)\n",
    "    sub = sub.drop('Unnamed: 0', axis=1)\n",
    "    sub.to_csv(path/comp/sub_name, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(path/comp/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n",
       "1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n",
       "2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n",
       "3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n",
       "4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n",
       "\n",
       "   identity_hate  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            0.5  \n",
       "3            0.5  \n",
       "4            0.5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(path/comp/f'submission_LSTM_glove_00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: Unnamed: 0, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"Unnamed: 0\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.987479</td>\n",
       "      <td>3.560071e-01</td>\n",
       "      <td>0.934285</td>\n",
       "      <td>5.253358e-02</td>\n",
       "      <td>0.815466</td>\n",
       "      <td>0.362029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>9.122054e-08</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>7.357243e-08</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>3.531618e-06</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>4.098626e-06</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>8.145207e-07</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>9.427390e-07</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>4.912997e-06</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>7.123228e-06</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
       "0  00001cee341fdb12  0.987479  3.560071e-01  0.934285  5.253358e-02  0.815466   \n",
       "1  0000247867823ef7  0.000545  9.122054e-08  0.000230  7.357243e-08  0.000070   \n",
       "2  00013b17ad220c46  0.004593  3.531618e-06  0.001200  4.098626e-06  0.000518   \n",
       "3  00017563c3f7919a  0.002925  8.145207e-07  0.000561  9.427390e-07  0.000283   \n",
       "4  00017695ad8997eb  0.006123  4.912997e-06  0.001186  7.123228e-06  0.000647   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.362029  \n",
       "1       0.000007  \n",
       "2       0.000057  \n",
       "3       0.000014  \n",
       "4       0.000056  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sub.drop('Unnamed: 0', axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "Model recompiled above and refitted - this time for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "159571/159571 [==============================] - 1601s 10ms/step - loss: 0.0597 - acc: 0.9790\n",
      "Epoch 2/2\n",
      "159571/159571 [==============================] - 1587s 10ms/step - loss: 0.0441 - acc: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9204089128>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 15s 101us/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_te], batch_size=1024, verbose=1)\n",
    "submission = pd.read_csv(path/comp/'sample_submission.csv')\n",
    "submission[list_classes] = y_test\n",
    "submission.to_csv(path/comp/'submission_LSTM_glove_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "checking columns (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in train.columns[2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "Looking at GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for o in open(path/EMBEDDING_FILE):\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for o in open(path/EMBEDDING_FILE):\n",
    "    temp = o\n",
    "    break\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " '0.418',\n",
       " '0.24968',\n",
       " '-0.41242',\n",
       " '0.1217',\n",
       " '0.34527',\n",
       " '-0.044457',\n",
       " '-0.49688',\n",
       " '-0.17862',\n",
       " '-0.00066023',\n",
       " '-0.6566',\n",
       " '0.27843',\n",
       " '-0.14767',\n",
       " '-0.55677',\n",
       " '0.14658',\n",
       " '-0.0095095',\n",
       " '0.011658',\n",
       " '0.10204',\n",
       " '-0.12792',\n",
       " '-0.8443',\n",
       " '-0.12181',\n",
       " '-0.016801',\n",
       " '-0.33279',\n",
       " '-0.1552',\n",
       " '-0.23131',\n",
       " '-0.19181',\n",
       " '-1.8823',\n",
       " '-0.76746',\n",
       " '0.099051',\n",
       " '-0.42125',\n",
       " '-0.19526',\n",
       " '4.0071',\n",
       " '-0.18594',\n",
       " '-0.52287',\n",
       " '-0.31681',\n",
       " '0.00059213',\n",
       " '0.0074449',\n",
       " '0.17778',\n",
       " '-0.15897',\n",
       " '0.012041',\n",
       " '-0.054223',\n",
       " '-0.29871',\n",
       " '-0.15749',\n",
       " '-0.34758',\n",
       " '-0.045637',\n",
       " '-0.44251',\n",
       " '0.18785',\n",
       " '0.0027849',\n",
       " '-0.18411',\n",
       " '-0.11514',\n",
       " '-0.78581']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.strip() # strips leading & trailing whitespace\n",
    "temp.strip().split() # split by whitespace & remove empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/2921893\n",
    "# * unpacks sequence into positional arguments\n",
    "# ** does the same, but with a dict &==> named args"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Aersu)",
   "language": "python",
   "name": "aersu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
