{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WNixalo | 20181108-9\n",
    "\n",
    "---\n",
    "\n",
    "This gets rank 255/938 on the kaggle planet amazon competition, @ **0.92367** pvt w/ a threshold of `0.25`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jupyter/.fastai/data/planet')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Config.data_path()/'planet'\n",
    "path.mkdir(exist_ok=True)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-init all if need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c haasad eidl7zip -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! 7za -bd -y -so x {path}/train-jpg.tar.7z | tar xf - -C {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install kaggle --upgrade\n",
    "# ! mkdir -p ~/.kaggle/\n",
    "# ! mv ~/kaggle.json ~/.kaggle/\n",
    "# ! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sample_submission_v2.csv.zip to /home/jupyter/.fastai/data/planet\n",
      "  0%|                                                | 0.00/154k [00:00<?, ?B/s]\n",
      "100%|████████████████████████████████████████| 154k/154k [00:00<00:00, 67.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# # download\n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train-jpg.tar.7z -p {path}  \n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f train_v2.csv -p {path}  \n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg.tar.7z -p {path}\n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test-jpg-additional.tar.7z -p {path}  \n",
    "# ! kaggle competitions download -c planet-understanding-the-amazon-from-space -f test_v2_file_mapping.csv -p {path}\n",
    "! kaggle competitions download -c planet-understanding-the-amazon-from-space -f sample_submission_v2.csv -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-jpg-additional.tar.7z  test_v2_file_mapping.csv.zip  train_v2.csv.zip\n",
      "test-jpg.tar.7z\t\t    train-jpg.tar.7z\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/jupyter/.fastai/data/planet/sample_submission_v2.csv.zip\n",
      "  inflating: /home/jupyter/.fastai/data/planet/sample_submission_v2.csv  \n",
      "  inflating: /home/jupyter/.fastai/data/planet/__MACOSX/._sample_submission_v2.csv  \n"
     ]
    }
   ],
   "source": [
    "# decompress & clean\n",
    "# ! unzip {path}/train_v2.csv.zip -d {path}\n",
    "# ! unzip {path}/test_v2_file_mapping.csv.zip -d {path}\n",
    "! unzip {path}/sample_submission_v2.csv.zip -d {path}\n",
    "# ! 7za -bd -y x {path}/train-jpg.tar.7z -o{path}\n",
    "# ! 7za -bd -y x {path}/test-jpg.tar.7z -o{path}\n",
    "# ! 7za -bd -y x {path}/test-jpg-additional.tar.7z -o{path}\n",
    "# ! tar -xf {path}/test-jpg-additional.tar -C {path}\n",
    "# ! tar -xf {path}/train-jpg.tar -C {path}\n",
    "# ! tar -xf {path}/test-jpg.tar -C {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {path}/*.zip\n",
    "# ! rm -rf {path}/*.7z\n",
    "# ! rm -rf {path}/*.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (ImageFileList.from_folder(path)\n",
    "       .label_from_csv('train_v2.csv', sep=' ', folder='train-jpg', suffix='.jpg')\n",
    "       .random_split_by_pct(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (src.datasets(ImageMultiDataset)\n",
    "        .transform(tfms, size=128)\n",
    "        .databunch().normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageMultiDataset of len 4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_ds.ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see how far I can get with a ResNet34 before going to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = models.resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a threshold of 0.25 got me best results last time, so I'll see if putting that will help get more accurate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/jupyter/.torch/models/resnet34-333f7ec4.pth\n",
      "100%|██████████| 87306240/87306240 [00:01<00:00, 55463352.89it/s]\n"
     ]
    }
   ],
   "source": [
    "f_score = partial(fbeta, thresh=0.25)\n",
    "learn = create_cnn(data, arch, metrics=[accuracy_thresh, f_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 05:08\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.118840    0.079255    0.985294         0.972470  (01:02)\n",
      "2      0.111048    0.062136    0.985294         0.946023  (01:01)\n",
      "3      0.102709    0.059693    0.970588         0.984375  (01:01)\n",
      "4      0.098300    0.045486    0.985294         0.968750  (01:01)\n",
      "5      0.091363    0.045031    0.985294         0.984375  (01:01)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-rn34-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 05:07\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.099128    0.056947    1.000000         0.934118  (01:01)\n",
      "2      0.100135    0.028738    1.000000         1.000000  (01:01)\n",
      "3      0.100602    0.040140    1.000000         1.000000  (01:01)\n",
      "4      0.093511    0.031510    1.000000         1.000000  (01:01)\n",
      "5      0.089607    0.028908    1.000000         1.000000  (01:01)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-rn34-all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 07:28\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.096939    0.035154    1.000000         1.000000  (01:30)\n",
      "2      0.095430    0.042647    1.000000         0.984375  (01:29)\n",
      "3      0.091046    0.028918    1.000000         1.000000  (01:29)\n",
      "4      0.088895    0.038921    1.000000         1.000000  (01:29)\n",
      "5      0.084451    0.033910    1.000000         1.000000  (01:29)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-5, lr/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2-rn34-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 07:28\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.086097    0.038472    1.000000         0.988095  (01:29)\n",
      "2      0.092633    0.033085    1.000000         0.984375  (01:29)\n",
      "3      0.087016    0.030257    1.000000         1.000000  (01:29)\n",
      "4      0.083042    0.035571    1.000000         1.000000  (01:29)\n",
      "5      0.080665    0.029056    1.000000         1.000000  (01:29)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-5, lr/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2-rn34-all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (src.datasets(ImageMultiDataset)\n",
    "        .transform(tfms, size=256)\n",
    "        .databunch().normalize(imagenet_stats))\n",
    "\n",
    "learn.data = data\n",
    "data.train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 16:38\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.088853    0.052580    1.000000         0.972470  (03:20)\n",
      "2      0.086033    0.053445    1.000000         0.943058  (03:19)\n",
      "3      0.086782    0.029156    1.000000         1.000000  (03:19)\n",
      "4      0.085321    0.035531    1.000000         0.972470  (03:19)\n",
      "5      0.079460    0.036163    1.000000         0.972470  (03:19)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-256-rn34-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 16:36\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.082377    0.039151    1.000000         0.972470  (03:19)\n",
      "2      0.083979    0.033664    1.000000         1.000000  (03:19)\n",
      "3      0.084648    0.045617    1.000000         0.972470  (03:19)\n",
      "4      0.082936    0.038716    1.000000         0.972470  (03:18)\n",
      "5      0.082616    0.034059    1.000000         0.972470  (03:19)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-256-rn34-all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 size 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23:02\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.084451    0.039155    1.000000         0.988095  (04:36)\n",
      "2      0.085343    0.054677    0.985294         0.958683  (04:36)\n",
      "3      0.084148    0.052638    0.985294         0.949743  (04:36)\n",
      "4      0.081343    0.032835    0.985294         0.988095  (04:36)\n",
      "5      0.076463    0.032336    1.000000         0.988095  (04:36)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-5, lr/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2-256-rn34-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 23:01\n",
      "epoch  train_loss  valid_loss  accuracy_thresh  fbeta   \n",
      "1      0.079911    0.045833    0.985294         0.972470  (04:36)\n",
      "2      0.079621    0.039752    1.000000         0.972470  (04:36)\n",
      "3      0.079370    0.031724    0.985294         0.988095  (04:36)\n",
      "4      0.074065    0.037323    0.985294         0.988095  (04:36)\n",
      "5      0.073343    0.039684    0.985294         0.988095  (04:36)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-5, lr/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2-256-rn34-all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('stage-2-256-rn34-all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2class = idx2class = {v:k for k,v in learn.data.train_ds.ds.class2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX  test-jpg\t       test_v2_file_mapping.csv  train_v2.csv\n",
      "models\t  test-jpg-additional  train-jpg\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df = pd.read_csv(path/'sample_submission_v2.csv')\n",
    "subdic = {c1:c2 for c1,c2 in zip(subm_df.image_name,subm_df.tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_test_datafolder(learner, test_folder):\n",
    "    learner.data = (src.add_test_folder(test_folder)\n",
    "                    .datasets(ImageMultiDataset)\n",
    "                    .transform(tfms, size=256)\n",
    "                    .databunch().normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st dataset portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 12:03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_test_datafolder(learn, 'test-jpg')\n",
    "raw_preds = learn.TTA(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([40669, 17]), torch.Size([40669, 17]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_preds), raw_preds[0].shape, raw_preds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = copy(raw_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [f.name.split('.')[0] for f in learn.data.test_ds.ds.x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd dataset portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 06:14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_test_datafolder(learn, 'test-jpg-additional')\n",
    "raw_preds = learn.TTA(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (torch.cat((preds[0],raw_preds[0])), torch.cat((preds[1],raw_preds[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: this will work:\n",
    "# preds = [torch.cat((preds[i],raw_preds[i])) for i in range(len(preds))]\n",
    "\n",
    "# # but this will leave you with a <generator object <genexpr> at 0x7f91696821a8>\n",
    "# preds = (torch.cat((preds[i],raw_preds[i])) for i in range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames.extend([f.name.split('.')[0] for f in learn.data.test_ds.ds.x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting predictions to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date = str(datetime.date.today()).replace('-','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.2775\n",
    "\n",
    "for i,fn in enumerate(fnames):\n",
    "    subdic[fn] = ' '.join(idx2class[cdx] for cdx in np.where(preds[0][i]>=th)[0])\n",
    "    \n",
    "subm_col = [subdic[fn] for fn in subm_df.image_name]\n",
    "subm_df.tags = subm_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir {path}/submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2.11M/2.11M [00:01<00:00, 1.27MB/s]\n",
      "Successfully submitted to Planet: Understanding the Amazon from Space"
     ]
    }
   ],
   "source": [
    "sub_name = f'planet_stage-2-256-rn34-all_{date}_th{str(th)}.csv'\n",
    "subm_df.to_csv(path/'submissions/'/sub_name, index=False, )\n",
    "! kaggle competitions submit -c planet-understanding-the-amazon-from-space -f {path}/submissions/{sub_name} -m \"fastai 1.0; 2-stg; RN34; threshold=\"{th}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'stage-2-256-rn34_1'|threshold|pvt score|rank|'stage-2-256-rn34'|pvt score|rank\n",
    "-|-|-|-|-|-|-|-|-\n",
    "#|0.5|0.89458|-|#|0.89430|-\n",
    "#|0.4|0.91274|-|#|-|-\n",
    "#|0.3|0.92177|-|#|0.92046|-\n",
    "#|0.2|0.91901|-|#|-|-\n",
    "#|0.25|0.92250|-|#|-|-\n",
    "#|0.2575|0.92255|-|#|0.92201|-\n",
    "\n",
    "Training on the entire dataset with a threshold of 0.25 gets **0.92367** pvt @ 255/983."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I may go to resnet50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
